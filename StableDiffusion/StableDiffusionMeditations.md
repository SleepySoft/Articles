# StableDiffusion - 沉思录

# 前言

在StableDiffusion出现后，我就开始使用它去绘制满足我XP的图。最初只是抄prompts，改瑟图。 
当时也写了几篇关于复现图片的文章，并且学到了一些操作，还处于一种知其然不知其所以然的状态。

直到2023年下半年，我才终于开始系统性地学习SD并尝试使用它进行一些创造性的活动。
我将我生成的图片分享到书上。不得不说，大家看美女的热情还是很高的。毕竟来某乎写文章这么多年才千粉，而在某书发瑟图半年就接近千粉了。。。

[我的小红书主页](https://www.xiaohongshu.com/user/profile/6474822f000000002a037365?xhsshare=CopyLink&appuid=6474822f000000002a037365&apptime=1704264015)

这篇文章包括“基本操作”和“改善技巧”两部分，这些都是我这些时间的经验总结。

注意：这并非一篇SD的入门文章或使用说明。

对于新手来说，你不可能靠这篇文章学会SD的使用，但它却能让你少走弯路。对于某些操作的不明白之处，可以等到接触到的时候再做实践。

对于AI绘画的同好们来说，这篇文章权当交流分享，期望与大家多多交流。

对于AI绘画的大牛来说，如果本文的描述出现谬误，请不吝赐教，及时指出我的错误。


# 基本操作

## 仔细阅读模型说明

我将这一条放在首位，因为这一条虽然简单，但却非常重要。因为像我这种见好就下，存有2T+模型的人来说，多而不精是一个很大的问题。

这里的模型主要包括主模型（Checkpoint）和LoRA。

对于主模型，大部分作者会在说明中写擅长什么风格，推荐使用什么采样器，推荐的采样步骤，推荐的反向提示词，等等。 
甚至有的模型会告诉你一些特殊事项，比如该模型的cfg scale设置不能高于3。仔细阅读说明，能让使用过程少走弯路。

对于LoRA，说明中最关键的部分是推荐的权重以及触发词（可能有可能没有），还有就是它是基于哪个模型训练的。
与该LoRA配合的主模型在关系上越接近它在训练时基于的主模型，那么出意外的概率就越小。

不同模型有不同的特性。比起不停地尝试不同风格的LoRA，将一个主模型的潜力挖掘干净，会更有利于水平提升。


## 下全常用的embedding模型

在刚开始抄prompts的时候，对于类似“EasyNegative”、“badhandv4”这样的反向提示词，我总觉得莫名其妙。
后来才知道这并不是普通的tag，而是embedding模型。缺少这些模型，自然无法复现出同样的效果。
而使用这些embedding模型，可以大大减少反向提示词的数量并提升出图效果。

这些模型可以去各种模型网站上找，也可以去huggingface上找个全集批量下载，例如：

https://huggingface.co/embed/negative/tree/main


## 使用ADetailer

这个插件可以说是仅次于ControlNet的神器，使用它可以减少95%的脸崩问题。
这个插件可以说是我打开WebUI后第一个使能的插件，无论出什么图，默认都会开启。
可以阅读这篇文章了解详情：

https://zhuanlan.zhihu.com/p/653745248


## 多看，多分析别人的Prompt，总结自己的创作模式

真正的创造性活动不是抽卡，而是将自己脑中的影像表现出来。等到抽卡玩到一定程度后，相信有人会反过来去学习美术，利用图生图和ControlNet进一步创作。

对于还没到这一步的我们而言，还是只能通过语言来描述我们的想法。在总结了多次出图的思路后，你会发现图片的创作都是有一定模式的，比如：

风格（可以由主模型或LoRA确定） -> 视角 -> 动作 -> 场景（背景，场景元素） -> 人物（发型，眼神，表情，服饰，配饰） -> 效果（颜色，滤镜）

而关于如何精确地描述这些，则需要我们去收集和收录各种词汇，而参考别人的prompt就是很好的一种方法。

我也为了这个目的写了一个程序，最近在持续改进中。只可惜我不会JS，无法集成到WebUi上：

https://zhuanlan.zhihu.com/p/632650375


## LoRA并非1+1+1=3，使用时慎重 

我在这里给出一个暴论：LoRA在大部分情使用场景中其实是玄学。

LoRA从原理上看，可以这么理解：

对模型A进行微调得到模型A’，基本等效于训练一个ΔA，使得A+ΔA=A’，其中的ΔA的参数量（秩）比A小（低）很多，这里的ΔA就是上面说的LoRA。

然而问题在于，如果我们使用的是模型B呢？

```模型B+ΔA=?```

还有就是，如果ΔA不使用满权重呢？

```模型A+0.8* ΔA=?```

更别说模型

```X+0.8* ΔA+0.8* ΔB=???```

而最后一种，却是最常见的用法。

所以说LoRA并非“插件”，并不是脸的LoRA + 手的LoRA + 背景LoRA + 衣服LoRA = 多种风格组合的画。

LoRA的融合是一件非常复杂的事情 ，多个LoRA的简单融合常常会导致画面崩溃。

更深入了解LoRA融合的原理，可以参考这篇文章：https://zhuanlan.zhihu.com/p/662147318


## 待续


# 改善技巧

## 对比和研究Checkpoint和LoRA的相性

如上面所说，“与该LoRA配合的主模型在关系上越接近它在训练时基于的主模型，那么出意外的概率就越小”。 但实际上我们但不可能去考究主模型的继承关系，并且上面那句话也并非绝对。

此外在作图过程中积累经验很重要的一点是：**识别精品（泛化性好，分层良好）和垃圾（过拟合）的主模型和LoRA，**

对于以上两点，一个非常好的实践就是多做XYZ图表。通过主模型和LoRA的交叉融合和对比，一方面可以发现好图的配方，另一方面我们能发现那些不好用的LoRA，并且不在它上面浪费时间。


## 提升出图细节

TODO


## 改善画手的问题

TODO


